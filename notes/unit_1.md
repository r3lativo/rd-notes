---
Date: 2024-02-20
Reviewed: true
week_lec: 1
---
- [[#Goals of the course]]
- [[#Preparing or identifying strong research]]
- [[#Importance of advance planning: examples]]
- [[#Critical Reading]]
    - [[#Main questions]]
    - [[#Consider also]]
    - [[#Early Career Researchers and Methods (Hubbard 2017) ]]
- [[#Scope]]
    - [[#Different sorts of research]]
    - [[#Pasteur’s Quadrant]]
- [[#Hypotheses]]
    - [[#Hypotheses' Role in Research Design]]
    - [[#Hypotheses' Role within a Research Program]]
    - [[#Formulation of Hypotheses: Structure]]
    - [[#Formulation of Hypotheses: vs. Mechanisms and Causality]]
    - [[#Advantages and Context of Use for Hypothesis-Driven Research]]
    - [[#Some research is not hypothesis-driven]]
    - [[#Example: Discovery Research in Neuroscience - The Brain at Rest]]
- [[#Hypothesis testing]]
    - [[#Why hypothesis is better?]]
- [[#Decision Table]]
    - [[#Correct Decision]]
    - [[#Type II error]]
    - [[#Type I error]]
- [[#Setting error-probabilities for Type I and Type II errors]]
- [[#Advancing by rejection]]

---

{% raw %}

### Goals of the course

In this course, our primary aim is to equip you with the skills to effectively utilize **research design and methods in addressing scientific inquiries.** Understanding research methods (RM) is crucial for devising research programs that can best tackle the underlying research questions.

The knowledge of research methods not only aids in the planning phase but also significantly enhances various aspects of research programs. This includes **refining** the research design, **selecting** appropriate items, **identifying** suitable participants, **conducting robust data analysis**, drawing **meaningful conclusions** from data, and presenting findings in a clear and informative manner.

By delving into research design principles and methodologies, you'll be empowered to navigate the complexities of scientific inquiry more confidently. This course will provide you with the necessary tools and insights to optimize every stage of the research process, ultimately fostering a more robust and impactful research program.

### Preparing or identifying strong research

To develop robust research, it's essential to craft or **identify strong hypotheses** that your research program will evaluate. These hypotheses should be addressed in the most effective manner possible, ensuring that your research design, variables, and data collection methods align with them.

It's imperative to demonstrate that your research is capable of addressing the stated hypotheses and that your conclusions are derived directly from the collected data. Expect thorough critical evaluation of these aspects throughout the research process.

**Effective planning well in advance is key to success.** Anticipate and prepare for critical reading by honing your critical thinking skills. This course will provide valuable guidance in interpreting and analyzing existing literature, enhancing your ability to engage critically with research materials.

> [!important] You should argue that the conclusions derive from the data

### Importance of advance planning: examples

Advance planning plays a critical role in research design. For instance, **selecting the most suitable design (1)** greatly impacts the power of our research program (RP), its ability to handle confounding variables, sensitivity, and applicable statistical analyses.

Similarly, **determining the sampling strategy (2)** is crucial. _While random sampling is often ideal, it's not always feasible or the best option_.

> [!important] Select the design and determine the sampling strategy!

Understanding and **defining parameters such as inclusion/exclusion criteria (3)** for participants and establishing pre/post-fact data cleaning rules are essential steps.

> One valuable approach is ==**pre-registration**==, **a process where researchers specify all research design elements before conducting the study**. This acts as a contract between the researcher and the scientific community, ensuring transparency and reducing bias. Platforms like the [Open Science Foundation](https://osf.io/) offer templates and repositories for depositing pre-registrations without the ability to alter them.
> 
> > [!important] For example, researchers working with Hasson Uri typically start by creating a comprehensive pre-registration of their data, outlining all aspects of the research design before proceeding.

## Critical Reading

When evaluating your research, critical readers will ask these questions:

### Main questions

1. **Statement and Implication:** What does the statement assert, and what are its implications?
2. **Supporting Data:** What type of data would either support or weaken the hypothesis being presented?
3. **Evidence:** What evidence is provided both for and against the proposition being made?
4. **Alternative Explanations:** Are there alternative explanations for the evidence presented?
5. **Applicability:** In what circumstances does the statement apply?
6. **Generalizability:** Do the circumstances in which the statement is addressed resemble those to which the statement would typically apply?
7. **Motives:** Are there other motives for asserting the statement beyond a valid interpretation of the data?

### Consider also

- **Clarity and Definitions:** Are the terms clearly defined, or are they vague? Are there any implied assumptions within the statement?
- **Comparative Terms:** Are comparative terms used sensibly and meaningfully within the context of the statement?
- **Evidence and Confirmation Bias:** Can the data presented be considered evidence for the proposition? Is there a risk of confirmation bias influencing the interpretation of the data?
- **Versatility of Data:** Can the same data be utilized to argue against the proposition as well?
- **Statement and Implication:** What does the statement assert, and what are its implications? Are the terms well-defined, or are they vague? Are there any implied assumptions? Are comparative terms used sensibly and meaningfully within the context of the statement?
- **Supporting Data:** What type of data would either support or weaken the hypothesis being presented? Can the data be used as evidence of anything? Is there evidence for confirmation bias in the data?
- **Evidence:** What evidence is provided both for and against the proposition being made? Can the same data be used to argue against the proposition?
- **Explanation and Causality:** Consider explanations from a causal mechanistic perspective. Are there alternative explanations? What are potential covariates, and have they been adequately controlled for?
- **Real-world Applicability:** Are the conclusions likely to explain what occurs in the real world?
- **Researcher Bias:** Do the researchers have a stake in supporting the research hypothesis?

> [!important] While conduction researches be aware of the
> 
> **confirmation bias:** asking question so that the result of the analyses will confirm our hypotheses

### Early Career Researchers and Methods (Hubbard 2017)

In a research about reading research papers (yes, lol), Hubbard underlined how throughout the academic career (from master students to postdocs and academics) difficulties and priorities change, but it is well evident the importance - and the associated difficulty - of understanding the methods.

> [!important] Early career researchers find it most difficult to understand Methods and Results [1].

Moreover, different sections of scientific papers are considered easy to read and important at different stages of academic careers, with methods seeing a huge peak between first and second year master students, and results (figures plus tables) placing at the first place in importance for academics.

> [!important] Figures and tables are extremely important.

![[Untitled 32.png|Untitled 32.png]]

Wordcloud extracted from advice given by researchers to someone reading a scientific paper for the first time. The size of the word is proportional to the frequency with which the word was mentioned.

## Scope

![[Untitled 1 20.png|Untitled 1 20.png]]

Sample topics

### Different sorts of research

Research can be categorized into various types based on its objectives and methods:

**Hypothesis-Driven** vs. **Descriptive/Discovery-Driven Research:**

- **Hypothesis-Driven Research:** Focuses on testing specific hypotheses derived from theoretical frameworks. It aims to confirm or refute predetermined hypotheses through systematic experimentation or observation.
- **Descriptive/Discovery-Driven Research:** Aims to explore and describe phenomena without necessarily testing specific hypotheses. This type of research is often exploratory in nature, seeking to uncover new patterns, trends, or relationships.

**Basic Research** vs. **Applied Research:**

- **Basic Research:** Often referred to as "pure science," basic research is grounded in the scientific method and aims to expand the existing body of knowledge. It seeks to understand fundamental principles and mechanisms without immediate practical applications.
- **Applied Research:** Focuses on solving specific problems or improving existing solutions. The primary goal is to address practical issues and create better solutions for real-world problems. Applied research often begins with a client's problem that requires research to find solutions.

### Pasteur’s Quadrant

  

![[Untitled 2 18.png|Untitled 2 18.png]]

Pasteur’s Quadrant

**Pasteur's quadrant exemplifies a synergy between applied goals and scientific rigor**, showcasing how practical solutions can emerge from scientific creativity.

> Pasteur's endeavors exemplify this approach. His innovations aimed at addressing real-world problems in wine production led to the invention of pasteurization, a process that eliminates bacteria by heating beverages. Additionally, Pasteur's research on weakening bacterial strains through inoculation paved the way for the development of vaccines against diseases such as anthrax, rabies, and cholera.

> [!important] Use-Inspired Basic Research: Pasteur never undertook a study that was not applied even if his researches changed forever the way we view the cause and prevention of disease.

## Hypotheses

A **formal** hypothesis is a statement about the world that can be either true or false. In practice, it's the statement whose validity is being investigated, typically in terms of its probability of being true.

A **descriptive** hypothesis is an idea that necessitates further examination.

There are several key points to note about hypotheses:

1. **Testability and Falsifiability:** Valid hypotheses must be testable, meaning they can be subjected to empirical investigation, and falsifiable, meaning it's possible to demonstrate that they are false.
2. **Derivation from Theories:** Single empirical hypotheses are usually derived from broader theories or intellectual frameworks. They serve as specific assertions that can be tested within the context of these theories.
3. **Distinct from Theories:** It's essential to distinguish between hypotheses and theories. Hypotheses are specific statements being tested, while theories are comprehensive explanations that integrate multiple hypotheses and empirical observations.

### **Hypotheses' Role in Research Design**

Hypotheses play a crucial role in shaping research design:

1. **📏 Extension of Theories:** Hypotheses typically build upon existing theories, providing specific assertions that can be empirically tested.
2. **🎯 Motivation for Design:** They serve as the driving force behind research design, guiding decisions on variables to manipulate and observe.
3. **👁️ Embodiment in Experimental Variables:** Hypotheses are embodied by the experimental variables, defining what can be manipulated and observed during the study.
4. **🔮 Focus in Psychology:** In psychology (Ψ), hypotheses often involve relationships between variables or different levels of a single variable.

### **Hypotheses' Role within a Research Program**

The progression of scientific inquiry heavily relies on hypotheses:

1. **✨ Initial observations inspire hypotheses**, which are formulated to explain or explore these observations.
2. **🚘** These **hypotheses** then **drive the direction of research**, dictating the methods and approaches used.
3. **🥷** Research endeavors produce **new data that challenges the initial hypothesis**, either supporting or weakening it.
4. **🔁** This process **generates new hypotheses** or prompts requests for replication, **fueling further investigation** and refinement of theories.
5. **🧠** It's important to **focus on conceptual independence** when formulating hypotheses, deriving them from fundamental concepts rather than solely from established methods, variables, or materials.

### Formulation of Hypotheses: Structure

Hypotheses…

1. can be about a **single value**, a comparative statement, a statement about association
2. should **avoid open-ended questions**
3. **cannot be phrased ambiguously**
    1. E.g., avoid statements like "iPhones are better than Android phones" which lack clear definitions or operationalization.
4. often involve **two levels of abstraction:**
    1. **Conceptual variables**: Address abstract concepts, such as the relationship between lack of sleep and loss of executive function.
    2. **Operational variables**: Phrased in terms of specific measures or conditions used in the study, such as "less than 6 hours of sleep reduces task-switching behavior."

### Formulation of Hypotheses: vs. Mechanisms and Causality

> [!important] **Cause and effect**
> 
> describe a relationship between two phenomena where one phenomenon is the reason for the occurrence of the other. _For instance, eating too much food (cause) leads to weight gain (effect)._

**In Psychology (Ψ)**, research aims to provide **causal-mechanistic explanations**, revealing the interactions between components that give rise to complex phenomena.

> [!important] These mechanistic explanations move beyond mere association to establish a causal relationship, although this perspective faces criticism.

Mechanistic and causal explanations can be applied at both **intra-level** (e.g., relations between cognitive processes) and **inter-level** (e.g., relations between brain and behavior) **interactions**.

### **Advantages and Context of Use for Hypothesis-Driven Research**

Let’s look at the benefits and suitability of hypothesis-driven research in various contexts, as well as potential strategies for dealing with situations where hypotheses are lacking:

1. Hypothesis-driven research is appropriate when **evaluating a limited number of mutually exclusive ideas**.
2. It is adequate for **testing very specific ideas**, such as determining how the impact of age on face processing depends on gender.
3. Specifying hypotheses in advance protects against fishing expeditions and produces designs that reduce biases, thereby **enhancing research quality**.
4. By ruling out possibilities, **hypothesis-driven research reduces uncertainty** and allows for clearer conclusions.
5. This approach is often designed to **provide explanations for observed phenomena**, moving beyond simple observations.

> [!important] If you have
> 
> **data but no hypothesis**, exploratory data analysis techniques can be employed to uncover patterns or relationships within the data. Alternatively, the data can inspire the formulation of hypotheses for future research.

### Some research is not hypothesis-driven

These points highlight the importance and diversity of non-hypothesis-driven research across various fields of study:

==**Descriptive (Observational) Research:**== Focuses on describing observations without testing specific hypotheses. It is sometimes perceived as information gathering rather than hypothesis testing; however, **observations are essential for developing more complex hypotheses**, serving as a foundation for further research inquiries.

- **Example:** Survey research focuses on uncovering facts or patterns, such as mean self-rated happiness in different countries or the propensity to engage in non-social behavior per economic brackets.
- **Fields** like archaeology, paleontology, and astronomy often have strong descriptive components, relying on observations to uncover patterns and trends.

> [!important] In neuroscience, observations play a crucial role in expanding our understanding of the brain and its functions.

==**Discovery Science**==**:** Focuses on identifying patterns in data without initially testing specific hypotheses.

==**Bottom-Up Mathematical Models**==**:** Reflect conceptual or nonconceptual models and attempt to account for observed data, allowing researchers to derive insights from empirical observations.

### **Example: Discovery Research in Neuroscience - The Brain at Rest**

Years ago, there was a notion that certain neurons were active when the brain was idle. This stemmed from the observation that certain brain areas were consistently more active when not engaged in any specific task. However, when a task was initiated, activity in these areas dipped below the baseline. This sparked curiosity about what cognitive process could cause such a shutdown in brain areas, leading to the emergence of the Default Mode Network (DMN).

Some researchers proposed that these areas might actually increase computation during rest, prompting an observational study to investigate if the mind at rest exhibited increased activation. Surprisingly, the study revealed that there was no heightened activity; instead, the brain exhibited uniform activity during rest, with oxygen extraction levels dipping below the baseline.

![[Untitled 3 15.png|Untitled 3 15.png]]

- During resting states, there is a **uniform level of oxygen extraction** in the brain, contrary to expectations of increased extraction. This phenomenon occurs even in regions typically deactivated during tasks.
- The **Default Mode Network (DMN)** exhibits reduced metabolic demands compared to baseline levels when task-deactivated. This indicates a decrease in activity rather than an increase above baseline levels during rest periods.

## Hypothesis testing

We're delving into the **significance of hypotheses in inferential statistics**, examining how we test them and determine whether a value is unexpected. But before diving in, let's grasp the basics.

> [!important] **Hypothesis testing lies at the heart of inferential statistics**
> 
> , where we draw conclusions from data.

It's a structured method for determining the validity of an idea. By analyzing our data, we discern which hypothesis - H1 or H0 - is better supported. **Essentially, we ask: are the data aligning more closely with H0 or H1?**

### Why hypothesis is better?

**Null Hypothesis (H0)**: This is a testable statement representing the current understanding in the field based on existing data. It's what you'd assume to be true without gathering more data to develop new theories. Often, H0 suggests an equivalence between categories or no effect.

**Alternative Hypothesis (H1)**: This offers a conflicting view to H0. It contradicts the null hypothesis.

> [!important] The premise of hypothesis testing is to demonstrate that there's a difference between the hypotheses rather than proving the null.

Instead of asking the probability of H0 or H1 being correct given the data $P(H|D)$, which might seem intuitive but is incorrect, we actually assess the probability of obtaining our data under a specific hypothesis $P(D|H)$. **Essentially, we're evaluating how likely it is to have our observed data given a particular hypothesis.**

The ==**decision rule**== defines how strict we are - when to reject H0 - and the relation between H0 and H1: how surprised would you be to discover that there is a specific data given a specific hypothesis (so, your knowledge up to that point)?.

> [!important] How strict we are, statistically speaking, means what is the probability it would happen: the “amount of surprise” we need in order to reject an hypothesis.

We might have an equivalence null hypothesis or a directional null hypothesis. **The relationship between H0 and H1 determines the level of surprise.**

> [!important] **We do not decide**
> 
> which of two properties is correct/true because the relationship between the hypothesis and the data is a probabilistic one: _it’s not our decision._

## Decision Table

The relationship between whatever we decide and the true state of affairs in the world is represented by a 2×2 decision table.

> [!important] It is important to remark that
> 
> **we never actually know or learn what is the** _**true**_ **state of affairs in the world** - but _there is one_, albeit hidden from us.

Given our decision, and in relation to the state of affairs in the world, we will be occupying one of these squares:

|Decision|**Null hypothesis is True/preferred**|**Alternative hypothesis is True/preferred**|
|---|---|---|
|Fail to reject null hypothesis (H0)|Correct Decision|==**Type II Error**==|
|Reject null hypothesis in favor of alternative hypothesis (H1)|==**Type I Error**==|Correct Decision|

Of course in the end it is our decision whether to reject H1 or H0; **most of the time we reject H0 because the data are so surprising that we cannot do else.**

Let’s discuss each possible state more in detail.

> [!important] To do this, we use the
> 
> **test of significance**, which estimates **how surprising (unlikely) the results are given H0.**

### **Correct Decision**

When we choose not to reject the null hypothesis, it's because we find it preferable based on our data. This suggests that we can't draw any new conclusions from our data unless we reject the prevailing view on a specific topic.

However, **when we reject the null hypothesis** in favor of the alternative, we should actually **draw new conclusions** about how the data can be explained by our hypothesis. Remember, this is based on the likelihood of our data given our hypothesis $P(D|H)$ We're essentially deriving new insights from our findings.

### ==**Type II error**==

> [!important] ==**Type II error**==
> 
> happens when **we keep the null hypothesis but we should actually reject it.** It is a f**alse negative**.

What are the actual reasons behind this?

- **Weakness of the study**: for example, in a study in which we give energy drink to our subjects, there could be not enough caffeine in them to have effect - despite caffeine have an effect _in general_;
- **Bad measure**: the questions we pose to our subjects are imprecise, vague…: we end up with similar data in two groups.
- Other…

> [!important] When we find ourself keeping the null hypothesis, we do not really understand what is going on in the world:
> 
> **failing to reject the null hypothesis leads to the impossibility to draw any conclusion from the effect.**

### ==**Type I error**==

> [!important] ==**Type I error**==
> 
> happens when **we reject the null hypothesis but we should actually keep it**. It is a **false positive**.

What kind of situation would lead us to this?

Let’s say that we reject the null hypothesis given the probability of it being true is less than 5% - AKA, the significance-level of the significance test $\alpha = 0.05$.

- **Hidden value:** maybe the difference that we found has to do with a different cause which we did not think about and on which we have no control: for example, with an energy drink given to subjects to improve performances in a test, we see that people that took it perform better; but in reality that group is made of mostly women, which happen to be more intelligent.
- **The sample is too small:** our data is, in the end, just sets of numbers. The impact of **outliers** on small sample of data can be very big.
- **Biases:** we can deduce different conclusion from data by deciding a different threshold for surprise - but this would lead to simply being rejected by the community. However, we could end up tweaking the data to fulfill our expectations, recomputing the difference between the H1 and H0 hypothesis.
    
    > [!important] If you tweak your data enough, you will find what you want to find
    
    - Another problem is that, for example, the data never totally rule out H0; they always say that its probability is very low.

> [!important] Doing many many test will eventually lead to find the kind of surprise we were expecting to find.

## Setting error-probabilities for ==Type I== and ==Type II== ==errors==

> [!important] ==**Type-II error**==
> 
> is denoted by $β$, and the probability of not committing the error is given by the **Power** _$(=1−β)$_.

If your study is so good that you are never going to commit a Type-II error, your power is 1.

**Statistical power**: is formally defined as the ability to appropriately reject the null and avoid Type-II error. We will _not_ delve into how to compute the statistical power of a study; **what we should know is that it is computable.**

> [!important] ==**Type-I error**==
> 
> are controlled for with $P(α)$, typically set at 5%. This is formally the **level of strictness**

How do we set the error probability? First of all we have to have some kind of knowledge: as said before, the **test of significance** estimates how surprising (unlikely) the results are given H0.

> Interesting: there are fields of applied science in which this threshold is considered too lax and you need a more strict value: in medicine and pharmaceutics they set it at 1% or even less; same thing could happen in astronautics.

> [!important] The actual way in which we can distinguish a Type I or II error is based on the statistical power, and this is a value which should be computed before the research.

Strict control of $α$ protects against false positives, but comes at cost: increasing likelihood of failing to reject the null when required.

**We usually fix** $α$ **and report Power.** “Power” is not a specific value: depending of the field it can change… however the reviewers are really concerned about low power.

## Advancing by rejection

Advancing by rejection is the best framework.

> [!important] The moment we reject an hypothesis because of the data,
> 
> **we reduce uncertainty about the world**.

Historically, the Empirical Method was based on collecting data and then going beyond the data by **Induction*** to speculate about patterns and relationships (so, $P(H|D)$).

> [!important] ***Induction**
> 
> here means to add data, so the process of reasoning from specific observations to broader generalizations or hypotheses about the underlying principles or patterns in the data.

Now, the method is extended with an **Hypothetico-deductive model** that advances by supporting/weakening hypotheses via experiments.

> [!important] There's a clear hierarchy in this approach: Theory leads to Hypothesis, which then generates Observational Predictions that are tested.
> 
> $$\text{Theory} → \text{Hypothesis} → \text{Derive Observational Predictions} → \text{Test}$$

Formally: **If theory A is correct, hypothesis H is supported**. So:

- if H is not supported then Theory A is incorrect.
- If H is supported theory A _could_ be true.

> [!important] ==**Straw-man null**==
> 
> : oftentimes, we find ourselves with set up methods that ’follow’ the rejection model but meant to confirm prior ideas. Beware the straw-man null, **an hypothesis which is easy to refute, so to end up with your own ideas.**
> 
> > People very rarely construct experiments in a way in which to more easily reject their own idea, as we human have a bias to confirm their conceptions.

{% endraw %}

